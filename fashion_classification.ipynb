{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\"><h1 style=\"text-align:center;color:black\"> Fashion style Classification Problem üì∑ üöÄ </h1> </div>\n",
    "The Dogs & Cats is a foundational problem for a basic CNN(convolutional neural network) model which involves classifying images as a fashion styles.The dataset can be used for learning how to develop,evaluate and use convolutional deep learning neural networks for classification of images. This includes how to develop a robust test harness for estimating the performance of the model, exploring improvements for the model by changing the paramters of the model, saving and loading the model to make predicitions on new data.\n",
    "\n",
    "![fashion](..//fashion_recognition/Datasets/dataset-cover.png)"
   ],
   "id": "8238ebe69468d0c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-warning\"><h2 style=\"text-align:Center;color:black\">Table of Content </h2> </div>\n",
    "\n",
    "1. [Introduction üí•](#1)\n",
    "1. [Data Description](#2)\n",
    "1. [Loading Librariesüìñ](#3)\n",
    "1. [Data ExtractionüìÅ](#4)\n",
    "1. [Data Explorationüìä](#5)\n",
    "1. [Train Test Split](#6)\n",
    "    1. [Using Dataframe](#7)\n",
    "    1. [Using Directory](#8)\n",
    "1. [Data Preparation üõ†Ô∏è](#9)\n",
    "    1. [Image Data Generator](#10)\n",
    "        1. [Using DataFrame](#11)\n",
    "        1. [Using Directory](#12)\n",
    "1. [Deep learning Model ‚öôÔ∏è](#13)\n",
    "    1. [Model Layers](#14)\n",
    "    1. [Callbacks](#15)\n",
    "    1. [Compile Model](#23)\n",
    "    1. [Fit Model](#16)\n",
    "    1. [Plot Result](#17)\n",
    "    1. [Evaluvation](#18)\n",
    "1. [Prediction](#19)\n",
    "    1. [Visualize Classified Images](#20)\n",
    "1. [Submission](#21)\n",
    "1. [Conclusion](#22)"
   ],
   "id": "7d04645546058b44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='1'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h2 style=\"text-align:center;color:black\"> Introduction üí•</h2> </div> \n",
    "\n",
    "In this notebook, we will discover how to develop a CNN to classify images of fashion_styles.\n",
    "\n",
    "We will follow this steps:\n",
    "\n",
    "* Load and prepare the images for training purpose.\n",
    "* Split data for training and validation purpose.\n",
    "* Apply Data Augmentation to the data.\n",
    "* Develop a CNN model using keras and how to choose various parameters for improving performance of the model.\n",
    "* Evaluate performance of our model.\n",
    "* Save and load a model for further predictions.\n",
    "* Draw the confusion matrix for trained model."
   ],
   "id": "8e332c2a851cdd5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='2'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Data Description </h2> </div>\n",
    "\n",
    "The training archive contains 44,110 images of dogs and cats.\n",
    "\n",
    "Train your algorithm on these files and predict the labels.\n"
   ],
   "id": "af765d55b070a60d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='3'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Loading Libraries </h2> </div>"
   ],
   "id": "2eb5912a336a10df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Basic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visuals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ],
   "id": "8eb01f9df3a00773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Define the source dir where the images come from\n",
    "source = '../fashion_recognition/Datasets/fashion-dataset/images'\n",
    "\n",
    "# We will save in this dir the files we select to train the model\n",
    "destination = '../fashion_recognition/Datasets/fashion-dataset/working'\n",
    "\n",
    "# We will classify in this dir the images classified by syle\n",
    "dataset_home = '../fashion_recognition/Datasets/fashion-dataset/train_test_styles/'"
   ],
   "id": "bd07ce4969f299ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "makedirs(destination, exist_ok=True)\n",
    "makedirs(dataset_home, exist_ok=True)"
   ],
   "id": "51219ef5df0f24af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#We remove files of previous executions\n",
    "for filename in os.listdir(destination):\n",
    "    os.remove(os.path.join(destination, filename))"
   ],
   "id": "2066a30df4d344be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for dirname, _, filenames in os.walk(dataset_home):\n",
    "    for filename in filenames:\n",
    "        os.remove(os.path.join(dirname, filename))"
   ],
   "id": "cf42cf309b526a5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='4'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Data Extraction </h2> </div>"
   ],
   "id": "f213bd00652f97d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "files = \"../fashion_recognition/Datasets/fashion-dataset/images/\"",
   "id": "99ac07d099e854a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading Images in a Dataframe",
   "id": "5c0e2e673ed5da32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#We create a dataframe with the info of the images in the datasets\n",
    "csv_dir = \"../fashion_recognition/Datasets/fashion-dataset/\"\n",
    "\n",
    "data = pd.read_csv(csv_dir + \"styles.csv\", sep=\";\")"
   ],
   "id": "57c6381e652fdac0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.head()",
   "id": "52eefcaccd0aa460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Name of the file\n",
    "data['filename_source'] = data['id'].astype(str) + '.jpg'\n",
    "\n",
    "#Name of the style\n",
    "data['label'] = data['usage']\n",
    "\n",
    "#Origin route\n",
    "data['source'] = source + '/' + data['filename_source']\n",
    "\n",
    "#Filename in the destination route. It contains the label + id\n",
    "data['filename_destination'] = data['usage'] + '.' + data['filename_source']\n",
    "\n",
    "#Destination route\n",
    "data['destination'] = destination + '/' + data['filename_destination']\n",
    "\n",
    "#We remove the cells we don't need\n",
    "data.drop(labels=['gender', 'masterCategory', 'subCategory', 'articleType',\n",
    "       'baseColour', 'season', 'year', 'usage', 'productDisplayName'], axis=1, inplace=True)"
   ],
   "id": "abb4631eeee1a856"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.info()",
   "id": "642a938ffc3df402"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#We delete the registers whose label is null\n",
    "data = data[data.label.notna()]"
   ],
   "id": "cdacdb4000c06ea9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#We check if we actually have an image file for the registers\n",
    "images = os.listdir(source)\n",
    "data['exists'] = data.filename_source.isin(images)\n",
    "\n",
    "data = data[data['exists'] == True]\n",
    "\n",
    "data.drop(labels='exists', axis=1, inplace=True)"
   ],
   "id": "b02028cb0d39e663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.groupby('label').count()",
   "id": "c469eaf44f3aba09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Casual style has many registers. We select only 4100\n",
    "casual_style = data[data['label'] == 'Casual'].sample(4100)"
   ],
   "id": "d8f048860ec1e041"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#There are registers with only a few registers. We select only the styles with more than 1000\n",
    "rest_styles = data[\n",
    "    (data['label'] == 'Ethnic') |\n",
    "    (data['label'] == 'Formal') |\n",
    "    (data['label'] == 'Sports')\n",
    "]"
   ],
   "id": "4b8d18c9e280fbb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = pd.concat([casual_style, rest_styles], ignore_index=True)",
   "id": "3bd6783f93276201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in data.index:\n",
    "    src_path = data['source'][i]\n",
    "    dst_path = data['destination'][i]\n",
    "    copyfile(src_path, dst_path)"
   ],
   "id": "983a0b8da7c0af49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='5'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Data Exploration </h2> </div>"
   ],
   "id": "c1b05fc730a22e16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we start by visualizing the variable of interest.\n",
    "\n",
    "Let's view more images in a grid format.\n",
    "\n",
    "<h5 style=\"text-align:center;color:Green\">We visualize few images of Casual Style. </h5>"
   ],
   "id": "4eafd1d0b49bbae9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "df_label = data[data['label'] == 'Casual'][['destination']]\n",
    "df_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    plt.subplot(1,10,i+1)    # the number of images in the grid is 10*10 (100)\n",
    "    filename = df_label['destination'][i]\n",
    "    image = imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Casual',fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "cf71e7c52d5229c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h5 style=\"text-align:center;color:Red\">We visualize few images of Etnic style. </h5>",
   "id": "bba156979e34922e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "df_label = data[data['label'] == 'Ethnic'][['destination']]\n",
    "df_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    plt.subplot(1,10,i+1)    # the number of images in the grid is 10*10 (100)\n",
    "    filename = df_label['destination'][i]\n",
    "    image = imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Ethnic',fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "da02a9ea3b90ffbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h5 style=\"text-align:center;color:Red\">We visualize few images of Sports style. </h5>",
   "id": "371801111949a7ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "df_label = data[data['label'] == 'Sports'][['destination']]\n",
    "df_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    plt.subplot(1,10,i+1)    # the number of images in the grid is 10*10 (100)\n",
    "    filename = df_label['destination'][i]\n",
    "    image = imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Sports',fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "6cf1c2e6602db121"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h5 style=\"text-align:center;color:Red\">We visualize few images of Formal style. </h5>",
   "id": "d0e435c16b631e00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "df_label = data[data['label'] == 'Formal'][['destination']]\n",
    "df_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    plt.subplot(1,10,i+1)    # the number of images in the grid is 10*10 (100)\n",
    "    filename = df_label['destination'][i]\n",
    "    image = imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Formal',fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "id": "337279bca17bcf3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Images are of varying size.\n",
    "\n",
    "Every time the cell is run different set of images will be displayed, one can scan the images of both categories. Presence of humans in some images could be a challenge for the model to classify.\n",
    "\n",
    "Some images have more than one cats or dogs respectively."
   ],
   "id": "da921ace00f18113"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='6'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Train Test Split </h2> </div>"
   ],
   "id": "64f7120d58c6dab4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='7'></a>\n",
    "<div class=\"alert alert-block alert-warning\"><h4 style=\"text-align:center;color:black\"> Using Dataframe </h4> </div>"
   ],
   "id": "6b68423cb567a5c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train test split using dataframe\n",
    "\n",
    "labels = data['label']\n",
    "\n",
    "X_train, X_temp = train_test_split(data, test_size=0.2, stratify=labels, random_state = 42)\n",
    "\n",
    "label_test_val = X_temp['label']\n",
    "\n",
    "X_test, X_val = train_test_split(X_temp, test_size=0.5, stratify=label_test_val, random_state = 42)\n",
    "\n",
    "print('The shape of train data',X_train.shape)\n",
    "print('The shape of test data',X_test.shape)\n",
    "print('The shape of validation data',X_val.shape)"
   ],
   "id": "a0a58781cd8f110"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will Create a barplot to see the class distrubtion in trainting dataset.",
   "id": "b8211928aa6387e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "labels = list(data.label.unique())\n",
    "\n",
    "label1,count1 = np.unique(X_train.label,return_counts=True)\n",
    "label2,count2 = np.unique(X_val.label,return_counts=True)\n",
    "label3,count3 = np.unique(X_test.label,return_counts=True)\n",
    "\n",
    "uni1 = pd.DataFrame(data=count1,index=labels,columns=['Count1'])\n",
    "uni2 = pd.DataFrame(data=count2,index=labels,columns=['Count2'])\n",
    "uni3 = pd.DataFrame(data=count3,index=labels,columns=['Count3'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,6),dpi=200)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "plt.subplot(131)\n",
    "sns.barplot(data=uni1,x=uni1.index,y='Count1',palette='icefire',width=0.2).set_title('Class distribution in Training set',fontsize=15)\n",
    "plt.xlabel('Labels',fontsize=12)\n",
    "plt.ylabel('Count',fontsize=12)\n",
    "\n",
    "plt.subplot(132)\n",
    "sns.barplot(data=uni2,x=uni2.index,y='Count2',palette='icefire',width=0.2).set_title('Class distribution in validation set',fontsize=15)\n",
    "plt.xlabel('Labels',fontsize=12)\n",
    "plt.ylabel('Count',fontsize=12)\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "sns.barplot(data=uni3,x=uni3.index,y='Count3',palette='icefire',width=0.2).set_title('Class distribution in Testing set',fontsize=15)\n",
    "plt.xlabel('Labels',fontsize=12)\n",
    "plt.ylabel('Count',fontsize=12)\n",
    "\n",
    "plt.show()"
   ],
   "id": "31fe930dfd232257"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "+<a id='8'></a>\n",
    "<div class=\"alert alert-block alert-warning\"><h4 style=\"text-align:center;color:black\"> Using Directory </h4> </div>"
   ],
   "id": "cc19e2da0d73f587"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create directories\n",
    "subdirs = ['train/', 'test/']"
   ],
   "id": "b7846db4fa34ab25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for subdir in subdirs:\n",
    "    # create label subdirectories\n",
    "    labeldirs = []\n",
    "    for label in labels:\n",
    "        labeldirs.append(label + '/')\n",
    "    for labldir in labeldirs:\n",
    "        newdir = dataset_home + subdir + labldir\n",
    "        makedirs(newdir, exist_ok=True)"
   ],
   "id": "89e96331ab039300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.2"
   ],
   "id": "4d137944365d911a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# copy training dataset images into subdirectories\n",
    "src_directory = '../fashion_recognition/Datasets/fashion-dataset/working'\n",
    "for file in listdir(src_directory):\n",
    "        src = src_directory + '/' + file\n",
    "        dst_dir = 'train/'\n",
    "        if random() < val_ratio:\n",
    "            dst_dir = 'test/'\n",
    "        if file.startswith('Casual'):\n",
    "            dst = dataset_home + dst_dir + 'Casual/' + file\n",
    "            copyfile(src, dst)\n",
    "        elif file.startswith('Ethnic'):\n",
    "            dst = dataset_home + dst_dir + 'Ethnic/' + file\n",
    "            copyfile(src, dst)\n",
    "        elif file.startswith('Formal'):\n",
    "            dst = dataset_home + dst_dir + 'Formal/' + file\n",
    "            copyfile(src, dst)\n",
    "        elif file.startswith('Sports'):\n",
    "            dst = dataset_home + dst_dir + 'Sports/' + file\n",
    "            copyfile(src, dst)"
   ],
   "id": "acf1797242190061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "path1 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/train/Casual\"\n",
    "path2 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/train/Ethnic\"\n",
    "path3 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/train/Formal\"\n",
    "path4 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/train/Sports\"\n",
    "path5 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/test/Casual\"\n",
    "path6 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/test/Ethnic\"\n",
    "path7 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/test/Formal\"\n",
    "path8 = \"../fashion_recognition/Datasets/fashion-dataset/train_test_styles/test/Sports\"\n",
    "\n",
    "\n",
    "print('Then number of Casual images in training data is' ,len(os.listdir(path1)))\n",
    "print('Then number of Ethnic images in training data is' ,len(os.listdir(path2)))\n",
    "print('Then number of Formal images in training data is' ,len(os.listdir(path3)))\n",
    "print('Then number of Sports images in training data is' ,len(os.listdir(path4)))\n",
    "print('Then number of Casual images in validation data is' ,len(os.listdir(path5)))\n",
    "print('Then number of Ethnic images in validation data is' ,len(os.listdir(path6)))\n",
    "print('Then number of Formal images in validation data is' ,len(os.listdir(path7)))\n",
    "print('Then number of Sports images in validation data is' ,len(os.listdir(path8)))\n"
   ],
   "id": "e3a03327e7160937"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='9'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Data Preparation </h2> </div>\n",
    "\n",
    "firstly, we will list out all the important parameters and respective values."
   ],
   "id": "e3e91aace97cf0a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# parameters\n",
    "image_size = 128\n",
    "image_channel = 3\n",
    "bat_size = 32"
   ],
   "id": "b6983de3d6640f21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='10'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\">Image Data Generator </h3> </div>\n",
    "\n",
    "* The data for will used by flow_from_dataframe and flow_from_directory.\n",
    "* The batch size is 32 and the image size is (128,128).\n"
   ],
   "id": "235f8b28733c689b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Creating image data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range = 15,\n",
    "                                    horizontal_flip = True,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    shear_range = 0.1,\n",
    "                                    fill_mode = 'reflect',\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ],
   "id": "b767fcdca62ca104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='11'></a>\n",
    "<div class=\"alert alert-block alert-warning\"><h4 style=\"text-align:center;color:black\"> Using Dataframe </h4> </div>"
   ],
   "id": "6ac60a4281ca08e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Applying image data gernerator to train and test data\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(X_train,\n",
    "                                                    directory = '../fashion_recognition/Datasets/fashion-dataset/working',\n",
    "                                                    x_col= 'filename_destination',\n",
    "                                                    y_col= 'label',\n",
    "                                                    batch_size = bat_size,\n",
    "                                                    target_size = (image_size,image_size)\n",
    "                                                   )\n",
    "val_generator = test_datagen.flow_from_dataframe(X_val, \n",
    "                                                 directory = '../fashion_recognition/Datasets/fashion-dataset/working',\n",
    "                                                 x_col= 'filename_destination',\n",
    "                                                 y_col= 'label',\n",
    "                                                 batch_size = bat_size,\n",
    "                                                 target_size = (image_size,image_size),\n",
    "                                                 shuffle=False\n",
    "                                                )\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(X_test, \n",
    "                                                  directory = '../fashion_recognition/Datasets/fashion-dataset/working',\n",
    "                                                  x_col= 'filename_destination',\n",
    "                                                  y_col= 'label',\n",
    "                                                  batch_size = bat_size,\n",
    "                                                  target_size = (image_size,image_size),\n",
    "                                                  shuffle=False\n",
    "                                                 )"
   ],
   "id": "10bf0e5a4979e351"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='12'></a>\n",
    "<div class=\"alert alert-block alert-warning\"><h4 style=\"text-align:center;color:black\"> Using Directory </h4> </div>"
   ],
   "id": "e1a5511ba882bfe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_gen = train_datagen.flow_from_directory('../fashion_recognition/Datasets/fashion-dataset/train_test_styles/train/',\n",
    "                                              class_mode='binary',\n",
    "                                              target_size = (image_size,image_size),\n",
    "                                              batch_size = bat_size,\n",
    "                                             )\n",
    "\n",
    "val_gen = test_datagen.flow_from_directory('../fashion_recognition/Datasets/fashion-dataset/train_test_styles/test/',\n",
    "                                          class_mode='binary',\n",
    "                                          batch_size = bat_size,\n",
    "                                          target_size = (image_size,image_size),\n",
    "                                          shuffle = False\n",
    "                                         )"
   ],
   "id": "3dffe7dcd5aa2d85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='13'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Deep Learning Model </h2> </div>"
   ],
   "id": "816af8a2e180208a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='14'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\">Model Layers </h3> </div>\n",
    "\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The architecture of the Cat vs Dog Image Classification model consists of the following Layers and components:\n",
    "\n",
    "#### Layers :\n",
    "* The input layer consist of a Conv2D with 32 filters and activation relu.\n",
    "* The model contain the 3 blocks of convolution with increasing filters and activation relu.\n",
    "* Each convolution block contains Batch Noramlization, Max pooling (pool_size = 2) and Dropout (0.2).\n",
    "* The fully connected layers contain Flatten layer, Dense layer with 512 units and a Dropout layer.\n",
    "* The output layer is a Dense layer with 2 units and softmax activation.\n",
    "\n",
    "#### Components:\n",
    "\n",
    "* **Input Layer:** Receives input images for classification.\n",
    "* **Convolutional Layers:** Extract features from the images through convolutional operations.\n",
    "* **Pooling Layers:** Reduce the spatial dimensions of the feature maps.\n",
    "* **Flatten Layer:** Convert the 2D feature maps into a 1D vector.\n",
    "* **Fully Connected Layers:** Perform classification using densely connected layers.\n",
    "* **Output Layer:** Provides the final prediction probabilities for each fashion style classes."
   ],
   "id": "d5d4fec4cac9a6d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape = (image_size,image_size,image_channel))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Bloack 1 \n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "# Block 2\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "# Block 3\n",
    "model.add(Conv2D(256,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected layers \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "id": "1f465448f7dd46b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='15'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Callbacks </h3> </div>\n",
    "we will be using two callbacks -\n",
    "\n",
    "* **ReduceLROnPlateau :** Reduce learning rate when a metric has stopped improving.\n",
    "* **EarlyStopping :** Stop training when a monitored metric has stopped improving."
   ],
   "id": "9082d8df2a8c421f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience=2,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr = 0.00001,\n",
    "                                            verbose = 1)\n",
    "\n",
    "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)"
   ],
   "id": "8681cd2616ac2ef9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='23'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Compile the model </h3> </div>\n",
    "Finally we will compile the model .There are 3 things to mention here : Optimizer,Loss, Metrics\n",
    "\n",
    "* **Optimizer** :- To minimize cost function we use different methods For ex :- like gradient descent, stochastic gradient descent. So these are call optimizers. We are using a default one here which is adam.\n",
    "‚Äã\n",
    "* **Loss** :- To make our model better we either minimize loss or maximize accuracy. Neural Networks always minimize loss. To measure it we can use different formulas like 'categorical_crossentropy' or 'binary_crossentropy'. Here I have used binary_crossentropy.\n",
    "‚Äã\n",
    "* **Metrics** :- This is to denote the measure of your model. Can be accuracy or some other metric."
   ],
   "id": "27ad8bcf336f5d37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])",
   "id": "978e33e2a51066d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='16'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Fit the model </h3> </div>\n",
    "\n",
    "We are now going to train our compiled model using the train iterator (train_generator) and use the val iterator (val_generator) as a validation dataset during training.\n",
    "\n",
    "The number of steps for the train and validation iterators must be specified. This is the number of batches that will comprise one epoch. This can be specified via the length of each iterator, and will be the total number of images in the train and validation directories divided by the batch size (32).\n",
    "\n",
    "The model will be fit for 30 epochs."
   ],
   "id": "3672d7f271f9dcbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "styles_model = model.fit(train_generator,\n",
    "                         validation_data = val_generator,\n",
    "                         callbacks=[early_stoping,learning_rate_reduction],\n",
    "                         epochs = 30,\n",
    "                         # steps_per_epoch = len(train_generator),\n",
    "                         # validation_steps = len(val_generaotor),\n",
    "                         )"
   ],
   "id": "d903cd5448658bac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='17'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Plot the results </h3> </div>"
   ],
   "id": "c5c3081e111ec997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plots for accuracy and Loss with epochs\n",
    "\n",
    "error = pd.DataFrame(styles_model.history)\n",
    "\n",
    "plt.figure(figsize=(18,5),dpi=200)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Cross Entropy Loss',fontsize=15)\n",
    "plt.xlabel('Epochs',fontsize=12)\n",
    "plt.ylabel('Loss',fontsize=12)\n",
    "plt.plot(error['loss'])\n",
    "plt.plot(error['val_loss'])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Classification Accuracy',fontsize=15)\n",
    "plt.xlabel('Epochs',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "plt.plot(error['accuracy'])\n",
    "plt.plot(error['val_accuracy'])\n",
    "\n",
    "plt.show()"
   ],
   "id": "1fd84dda57293f11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='18'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Evaluvation </h3> </div>\n",
    "\n",
    "we will evaluvate the Training and validation data accuracy and loss."
   ],
   "id": "6c3c3be909f57753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluvate for train generator\n",
    "loss,acc = model.evaluate(train_generator,batch_size = bat_size, verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for training data is:',acc*100)\n",
    "print('The Loss of the model for training data is:',loss)\n",
    "\n",
    "# Evaluvate for validation generator\n",
    "loss,acc = model.evaluate(val_generator,batch_size = bat_size, verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for validation data is:',acc*100)\n",
    "print('The Loss of the model for validation data is:',loss)"
   ],
   "id": "5f6131701e61afd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we will save the model for future use.",
   "id": "22a9892a3dda3d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the Model\n",
    "model.save(\"model.h5\")"
   ],
   "id": "ab6abaee2b747b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='19'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Prediction </h2> </div>\n",
    "\n",
    "Now, we will predict the model on test dataset."
   ],
   "id": "dc270d50445dc8bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# prediction\n",
    "result = model.predict(test_generator,batch_size = bat_size,verbose = 0)\n",
    "\n",
    "y_pred = np.argmax(result, axis = 1)\n",
    "\n",
    "y_true = test_generator.labels\n",
    "\n",
    "# Evaluvate\n",
    "loss,acc = model.evaluate(test_generator, batch_size = bat_size, verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for testing data is:',acc*100)\n",
    "print('The Loss of the model for testing data is:',loss)"
   ],
   "id": "21c4bdec1afeebe1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classification report",
   "id": "31747789ffb666c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(classification_report(y_true, y_pred,target_names=labels))",
   "id": "1e0a63908b728959"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "confusioin matrix",
   "id": "bdb27539bb76ea4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "confusion_mtx = confusion_matrix(y_true,y_pred) \n",
    "\n",
    "f,ax = plt.subplots(figsize = (8,4),dpi=200)\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.1, cmap = \"gist_yarg_r\", linecolor=\"black\", fmt='.0f', ax=ax,cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel(\"Predicted Label\",fontsize=10)\n",
    "plt.ylabel(\"True Label\",fontsize=10)\n",
    "plt.title(\"Confusion Matrix\",fontsize=13)\n",
    "\n",
    "plt.show()"
   ],
   "id": "a7b7a435fc541a61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='20'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> submission </h2> </div>\n",
    "Make predictions on kaggle test data for submission."
   ],
   "id": "42c54691d1cf9a04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "size =(128,128)\n",
    "\n",
    "# loading into dataframe\n",
    "test_dir = \"../fashion_recognition/working/test1/\"\n",
    "filenames = os.listdir(test_dir)\n",
    "test_data = pd.DataFrame({\"filename\": filenames})\n",
    "test_data['label'] = 'unknown'"
   ],
   "id": "559cc50991fe841f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# Create data genenerator for test data\n",
    "test1_idg =  test_datagen.flow_from_dataframe(test_data, \n",
    "                                     \"../fashion_recognition/working/test1/\",\n",
    "                                     x_col= \"filename\",\n",
    "                                     y_col = 'label',\n",
    "                                     batch_size = bat_size,\n",
    "                                     target_size=size, \n",
    "                                     shuffle = False)\n",
    "\n",
    "# Test Prediction\n",
    "test1_predict = model.predict(test1_idg,verbose = 0)\n",
    "\n",
    "test1_predict_argmax = np.argmax(test1_predict, axis=1)\n",
    "\n",
    "y_test_pred = test1_predict_argmax\n",
    "\n",
    "test_data['label'] = y_test_pred\n",
    "\n",
    "# mapping\n",
    "label_mapping = {0: 'cat', 1: 'dog'}\n",
    "test_data['label'] = test_data['label'].map(label_mapping)\n",
    "test_data.head()\n",
    "\n",
    "# csv file output for submission\n",
    "sub = pd.read_csv('../fashion_recognition/Datasets/sampleSubmission.csv',index_col='id')\n",
    "\n",
    "sub['label'] = y_test_pred\n",
    "\n",
    "sub.to_csv('../fashion_recognition/Datasets/submission.csv',index=True)"
   ],
   "id": "46c253f82dab803b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id='21'></a>\n",
    "<div class=\"alert alert-block alert-danger\"><h3 style=\"text-align:center;color:black\"> Visualize Classified Images  </h3> </div>"
   ],
   "id": "632c5f9f6dcb77d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(1, 10, figsize=(20, 4))\n",
    "for idx in range(10):\n",
    "    image_path = os.path.join(test_dir, test_data.iloc[idx]['filename'])\n",
    "    image = Image.open(image_path)\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].set_title(\"Label: \" + test_data.iloc[idx]['label'])\n",
    "    axes[idx].axis('off')\n",
    "plt.show()"
   ],
   "id": "199ec9d047d00a3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After watching the images we can see the our model is quite accurate with 94% accuracy.",
   "id": "7d7bc7def63f9d64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "<a id='22'></a>\n",
    "<div class=\"alert alert-block alert-info\"><h2 style=\"text-align:center;color:black\"> Conclusion </h2> </div>\n",
    "\n",
    "\n",
    "We successfully built a deep neural network model by implementing Convolutional Neural Network (CNN) to classify dog and cat images with very high accuracy 97.32 %. \n",
    "\n",
    "The model was used to predict the classes of the images from the independent test set and results were submitted to test the accuracy of the prediction with fresh data.\n",
    "\n",
    "The Cat vs Dog Image Classification model demonstrates the successful implementation of a Convolutional Neural Network for image classification tasks. By accurately distinguishing between images of cats and dogs, this project showcases the potential of deep learning algorithms in solving real-world problems involving image analysis. Through this project, we aim to inspire further exploration of CNNs and their applications in various domains,"
   ],
   "id": "d1871eab5653fe5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
